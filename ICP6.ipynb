{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPkmd+wWjV50WJT6r+epExt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaiVarun1125/Big-Data-Analytics/blob/main/ICP6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl6FsGMb5iIy",
        "outputId": "f346676b-98e7-40c8-df1a-63d3d43f072d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing required libraries\n",
        "import pandas as pd;\n",
        "import keras"
      ],
      "metadata": {
        "id": "7YN0wdoT7n6c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting the file path\n",
        "file_path=\"/content/drive/My Drive/CSV/diabetes.csv\"\n",
        "dataset=pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "rgU-zFeb7HrP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the required libraries and modules\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kmk_mD3M7gld"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset here\n",
        "dataset = pd.read_csv(file_path, header=None).values"
      ],
      "metadata": {
        "id": "2xjWMc5np7mo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "#Creating the model\n",
        "my_first_nn = Sequential()\n",
        "\n",
        "#Adding Hidden Layer with relu activation function\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu'))\n",
        "\n",
        "#Adding the output layer with sigmoid activation function\n",
        "my_first_nn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#Compiling and fitting the model\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn.fit(X_train, Y_train, epochs=100,initial_epoch=0)\n",
        "\n",
        "#Printing out the output\n",
        "loss,accuracy= my_first_nn.evaluate(X_test, Y_test)\n",
        "print(\"Loss:\",loss)\n",
        "print(\"Accuracy:\",accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFK-NozVqJuJ",
        "outputId": "3446a238-efe7-45e2-eef2-1d820fbae882"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 3ms/step - loss: 12.0128 - acc: 0.6580\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 5.5609 - acc: 0.4931\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 4.3039 - acc: 0.4861\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 3.4419 - acc: 0.5278\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.8425 - acc: 0.5347\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.3000 - acc: 0.5642\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.8448 - acc: 0.5608\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.5475 - acc: 0.5660\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3179 - acc: 0.5851\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.2178 - acc: 0.6181\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1184 - acc: 0.6250\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.0580 - acc: 0.6354\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.0099 - acc: 0.6233\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9736 - acc: 0.6267\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9346 - acc: 0.6215\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.9209 - acc: 0.6562\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8866 - acc: 0.6406\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8680 - acc: 0.6441\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.9073 - acc: 0.6441\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8533 - acc: 0.6233\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8233 - acc: 0.6458\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7810 - acc: 0.6562\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7869 - acc: 0.6406\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7682 - acc: 0.6545\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7595 - acc: 0.6788\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7556 - acc: 0.6684\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7432 - acc: 0.6528\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7233 - acc: 0.6736\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7236 - acc: 0.6684\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7115 - acc: 0.6719\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7347 - acc: 0.6736\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6847 - acc: 0.6788\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7142 - acc: 0.6649\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6904 - acc: 0.6736\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6856 - acc: 0.6840\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6924 - acc: 0.6840\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6628 - acc: 0.6806\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6541 - acc: 0.6979\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6585 - acc: 0.6823\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6845 - acc: 0.6719\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6578 - acc: 0.6944\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6468 - acc: 0.6892\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7065 - acc: 0.6823\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6836 - acc: 0.6545\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6475 - acc: 0.6910\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6417 - acc: 0.6910\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6492 - acc: 0.6753\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6377 - acc: 0.6910\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6413 - acc: 0.6962\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6313 - acc: 0.6858\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6251 - acc: 0.7014\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6138 - acc: 0.6962\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6266 - acc: 0.6892\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6127 - acc: 0.6927\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6136 - acc: 0.6875\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6129 - acc: 0.6892\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6118 - acc: 0.7083\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6236 - acc: 0.6962\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6255 - acc: 0.6997\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6066 - acc: 0.7083\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6318 - acc: 0.7031\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6172 - acc: 0.6892\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6090 - acc: 0.7031\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6112 - acc: 0.6944\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6056 - acc: 0.7049\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5998 - acc: 0.7031\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5882 - acc: 0.7014\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5912 - acc: 0.7135\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5991 - acc: 0.7049\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6151 - acc: 0.6979\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5978 - acc: 0.7083\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5937 - acc: 0.7118\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5949 - acc: 0.6910\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5919 - acc: 0.7240\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6023 - acc: 0.7066\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6312 - acc: 0.6771\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6101 - acc: 0.7031\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5754 - acc: 0.7170\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5961 - acc: 0.7083\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6082 - acc: 0.7170\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6063 - acc: 0.6927\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6004 - acc: 0.7153\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5770 - acc: 0.7274\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6271 - acc: 0.7170\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5862 - acc: 0.7083\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5744 - acc: 0.7118\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6104 - acc: 0.6997\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5743 - acc: 0.7083\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5754 - acc: 0.7222\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5939 - acc: 0.7222\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6115 - acc: 0.7049\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6293 - acc: 0.7066\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6007 - acc: 0.6979\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5846 - acc: 0.7170\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5832 - acc: 0.7031\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5795 - acc: 0.7240\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5710 - acc: 0.7153\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5728 - acc: 0.7118\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5743 - acc: 0.7014\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5974 - acc: 0.7066\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7063 - acc: 0.6615\n",
            "Loss: 0.706335723400116\n",
            "Accuracy: 0.6614583134651184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing datasets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8], test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "\n",
        "# Creating the model\n",
        "my_first_nn = Sequential()\n",
        "\n",
        "# Adding hidden layer with the relu activation function\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu'))\n",
        "\n",
        "# Adding another Hidden layer with the tanh activation function\n",
        "my_first_nn.add(Dense(20, activation='tanh'))\n",
        "\n",
        "#Adding another Hidden layer with the sigmoid activation function\n",
        "my_first_nn.add(Dense(20, activation='sigmoid'))\n",
        "\n",
        "# Output Layer with sigmoid activation function\n",
        "my_first_nn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#Compiling and fitting the model\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn.fit(X_train, Y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "loss,accuracy = my_first_nn.evaluate(X_test, Y_test)\n",
        "#Printing out the output\n",
        "print(\"Loss:\",loss)\n",
        "print(\"Accuracy:\",accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgFgYWm8idxS",
        "outputId": "9dec7911-86f0-4ea9-fa47-1241f5d3437a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 3ms/step - loss: 0.6954 - acc: 0.5017\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6357 - acc: 0.6615\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6294 - acc: 0.6615\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6271 - acc: 0.6615\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6269 - acc: 0.6597\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6230 - acc: 0.6615\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6235 - acc: 0.6615\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6215 - acc: 0.6615\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6172 - acc: 0.6649\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6189 - acc: 0.6684\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6155 - acc: 0.6736\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6149 - acc: 0.6701\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6131 - acc: 0.6719\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6093 - acc: 0.6788\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6064 - acc: 0.6875\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6050 - acc: 0.6858\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6038 - acc: 0.6927\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6041 - acc: 0.6875\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6028 - acc: 0.6910\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6009 - acc: 0.6910\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5987 - acc: 0.6962\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5974 - acc: 0.6962\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5980 - acc: 0.6910\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5980 - acc: 0.7066\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5991 - acc: 0.6979\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5917 - acc: 0.6997\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5940 - acc: 0.7014\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5920 - acc: 0.7014\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5959 - acc: 0.6997\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5893 - acc: 0.7014\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5895 - acc: 0.6997\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5850 - acc: 0.6997\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5912 - acc: 0.7066\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5827 - acc: 0.6979\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5832 - acc: 0.7014\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5772 - acc: 0.6997\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5797 - acc: 0.6997\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5741 - acc: 0.7031\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5777 - acc: 0.6997\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5766 - acc: 0.7066\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5763 - acc: 0.7031\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5779 - acc: 0.7014\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5700 - acc: 0.7031\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5702 - acc: 0.7014\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5686 - acc: 0.7031\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5742 - acc: 0.7031\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5656 - acc: 0.6997\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5661 - acc: 0.7083\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5615 - acc: 0.7066\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5620 - acc: 0.7031\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5610 - acc: 0.7031\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5684 - acc: 0.7049\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5899 - acc: 0.7031\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5660 - acc: 0.7066\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5773 - acc: 0.6962\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5630 - acc: 0.7014\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5595 - acc: 0.7066\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5525 - acc: 0.7118\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5545 - acc: 0.7101\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5518 - acc: 0.7118\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5494 - acc: 0.7135\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5465 - acc: 0.7135\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5447 - acc: 0.7170\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5419 - acc: 0.7135\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5470 - acc: 0.7031\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5494 - acc: 0.7118\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5440 - acc: 0.7101\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5386 - acc: 0.7153\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5411 - acc: 0.7031\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5465 - acc: 0.7257\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5427 - acc: 0.7135\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5445 - acc: 0.7083\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5462 - acc: 0.7066\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5379 - acc: 0.7153\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5349 - acc: 0.7170\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5351 - acc: 0.7153\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5283 - acc: 0.7326\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5346 - acc: 0.7257\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5418 - acc: 0.7101\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5388 - acc: 0.7101\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5369 - acc: 0.7188\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5293 - acc: 0.7222\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5251 - acc: 0.7326\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5240 - acc: 0.7344\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5227 - acc: 0.7344\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5194 - acc: 0.7361\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5264 - acc: 0.7309\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5252 - acc: 0.7396\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5215 - acc: 0.7465\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5231 - acc: 0.7361\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5195 - acc: 0.7413\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5167 - acc: 0.7396\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5290 - acc: 0.7431\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5242 - acc: 0.7326\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5185 - acc: 0.7483\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5173 - acc: 0.7656\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5173 - acc: 0.7413\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5182 - acc: 0.7413\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5146 - acc: 0.7465\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5062 - acc: 0.7639\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5883 - acc: 0.6927\n",
            "Loss: 0.5882964134216309\n",
            "Accuracy: 0.6927083134651184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2"
      ],
      "metadata": {
        "id": "XLqGGmmNoxZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#Converting each image of shape (28*28) to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "\n",
        "#scale data\n",
        "train_data /=255.0\n",
        "test_data /=255.0\n",
        "\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "\n",
        "#Adding the hidden layer with relu activation function\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "\n",
        "#Adding another hidden layer with tanh activation function\n",
        "model.add(Dense(512, activation='tanh'))\n",
        "\n",
        "#Adding another hidden layer again with tanh activation function\n",
        "model.add(Dense(512, activation='tanh'))\n",
        "\n",
        "#Adding out layer with softmax activation function.\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compiling and fitting the model\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,validation_data=(test_data, test_labels_one_hot))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCV6HjUZ_sOq",
        "outputId": "a21df993-5579-4fa9-d49f-f85457af758a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "784\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 2s 5ms/step - loss: 0.2838 - accuracy: 0.9117 - val_loss: 0.1253 - val_accuracy: 0.9603\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0935 - accuracy: 0.9709 - val_loss: 0.1263 - val_accuracy: 0.9609\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 0.9811 - val_loss: 0.0802 - val_accuracy: 0.9758\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0432 - accuracy: 0.9860 - val_loss: 0.0805 - val_accuracy: 0.9775\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.0812 - val_accuracy: 0.9790\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0788 - val_accuracy: 0.9787\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.1246 - val_accuracy: 0.9706\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0799 - val_accuracy: 0.9803\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.0826 - val_accuracy: 0.9793\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0879 - val_accuracy: 0.9815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_data.shape[0],dimData)\n",
        "\n",
        "#convert data to float\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "\n",
        "#Adding the hidden layer with relu activation function\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "\n",
        "#Adding the another hidden layer again with relu activation function\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "#Adding output layer with softmax activation function\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compiling and fitting the model\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,validation_data=(test_data, test_labels_one_hot))\n"
      ],
      "metadata": {
        "id": "nHJW3DYVBPCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "953bdd33-3478-4e08-bd19-b864286555fa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "784\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 2s 5ms/step - loss: 6.2278 - accuracy: 0.8745 - val_loss: 0.7741 - val_accuracy: 0.9139\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.4368 - accuracy: 0.9476 - val_loss: 0.5395 - val_accuracy: 0.9253\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2495 - accuracy: 0.9603 - val_loss: 0.3433 - val_accuracy: 0.9475\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.1908 - accuracy: 0.9668 - val_loss: 0.3086 - val_accuracy: 0.9535\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.1583 - accuracy: 0.9717 - val_loss: 0.2458 - val_accuracy: 0.9666\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.1429 - accuracy: 0.9752 - val_loss: 0.5340 - val_accuracy: 0.9429\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1299 - accuracy: 0.9790 - val_loss: 0.2975 - val_accuracy: 0.9648\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1149 - accuracy: 0.9822 - val_loss: 0.3519 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1183 - accuracy: 0.9829 - val_loss: 0.2872 - val_accuracy: 0.9711\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1114 - accuracy: 0.9846 - val_loss: 0.6533 - val_accuracy: 0.9599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Choosing an image from the test data\n",
        "true_label = test_labels[0]\n",
        "\n",
        "#Reshaping the image to its original 28x28 shape (for visualization)\n",
        "original_image = test_images[0]\n",
        "\n",
        "#Ploting the original image\n",
        "plt.imshow(original_image, cmap='gray')\n",
        "plt.title(f'True Label: {true_label}')\n",
        "plt.show()\n",
        "\n",
        "#Making a prediction on the chosen image\n",
        "prediction = model.predict(np.expand_dims(image_to_predict, axis=0))\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "#Printing the prediction\n",
        "print(f'Predicted Label: {predicted_label}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Cu7KsU89gm_M",
        "outputId": "72a27baf-d5a8-4780-d9c7-b50b81038955"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n",
            "Predicted Label: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6FgYfYoCm89C"
      }
    }
  ]
}